#!/usr/bin/env bash
# -----------------------------------------------------------------------------
#  Nextstrain H5N1 wholeโgenome wrapper โ FHI custom version
# -----------------------------------------------------------------------------
#  โข Downloads metadata & FASTA from the Nโdrive
#  โข Converts / cleans metadata + splits FASTA by segment
#  โข Runs the customised Nextstrain avianโflu build
#  โข Uploads the resulting Auspice JSONs back to the Nโdrive
# -----------------------------------------------------------------------------
#  Usage (manual metadata / FASTA):
#     ./nextstrain_avian_whole_genome_wrapper.sh metadata.xls sequences.fasta
#  If the two arguments are omitted, the script will try to autodetect the files
#  in the SMB download directory.
# -----------------------------------------------------------------------------
set -Eeuo pipefail
IFS=$'\n\t'

# โโโโโโโโโโโโโโโโโโโโ General settings โโโโโโโโโโโโโโโโโโโโ
DATE=$(date +%F)                            # e.g. 2025โ04โ25
BASE_DIR="/mnt/tempdata"                  # Base scratch area
WORK_DIR="${BASE_DIR}/avianflu_nextstrain" # Holds raw input data
OUT_DIR="${BASE_DIR}/avianflu_nextstrain_out/${DATE}" # Holds final Auspice JSONs

# SMB share (adjust if moved)
SMB_HOST="//Pos1-fhi-svm01/styrt"
SMB_AUTH="$HOME/.smbcreds"                # username/password file
SMB_SOURCE="Virologi/NGS/tmp/avianflu_nextstrain"
SMB_TARGET="Virologi/NGS/1-NGS-Analyser/1-Rutine/2-Resultater/Influensa/11-Nextstrain/${DATE}_Nextstrain_Build"

# Git repos
NGS_SCRIPTS="$HOME/ngs_scripts"           # FHI helper scripts
AVIAN_REPO="${BASE_DIR}/avian-flu"        # Nextstrain avian influenza repo

# Conda env
CONDA_ENV="SNAKEMAKE"                     # Name of the conda env with Snakemake

# โโโโโโโโโโโโโโโโโโโโ Helper functions โโโโโโโโโโโโโโโโโโโโ
require()     { command -v "$1" &>/dev/null || { echo "โ '$1' not found" >&2; exit 1; }; }
clone_update() {
    local repo="$1" dest="$2" branch="${3:-main}"
    if [[ -d "$dest/.git" ]]; then
        git -C "$dest" fetch origin "$branch"
        git -C "$dest" pull --ff-only origin "$branch"
    else
        git clone --branch "$branch" --depth 1 "$repo" "$dest"
    fi
}

# โโโโโโโโโโโโโโโโโโโโ Preโflight checks โโโโโโโโโโโโโโโโโโโ
REQUIRED_CMDS=(git smbclient conda python3)
for c in "${REQUIRED_CMDS[@]}"; do require "$c"; done
mkdir -p "$WORK_DIR" "$OUT_DIR"

# โโโโโโโโโโโโโโโโโโโโ Activate conda โโโโโโโโโโโโโโโโโโโโโโ
source "$HOME/miniconda3/etc/profile.d/conda.sh"
conda activate "$CONDA_ENV"
require snakemake            # Now snakemake must be available via the env

# โโโโโโโโโโโโโโโโโโโโ Get code โโโโโโโโโโโโโโโโโโโโโโโโโโโโ
clone_update "https://github.com/folkehelseinstituttet/ngs_scripts.git" "$NGS_SCRIPTS" "main"
clone_update "https://github.com/nextstrain/avian-flu.git" "$AVIAN_REPO" "master"

# โโโโโโโโโโโโโโโโโโโโ Download data โโโโโโโโโโโโโโโโโโโโโโโ
echo "๐๏ธ  Fetching metadata & FASTA from SMB share โฆ"
smbclient "$SMB_HOST" -A "$SMB_AUTH" -D "$SMB_SOURCE" <<EOF
prompt OFF
recurse ON
lcd $WORK_DIR
mget *
EOF

# โโโโโโโโโโโโโโโโโโโโ Resolve input paths โโโโโโโโโโโโโโโโโ
if [[ $# -eq 2 ]]; then
    META_XLS="$1"
    SEQ_FASTA="$2"
else
    META_XLS="$(find "$WORK_DIR" -maxdepth 1 -iname '*.xls'   | head -n1)"
    SEQ_FASTA="$(find "$WORK_DIR" -maxdepth 1 -iname '*.fasta' | head -n1)"
fi

[[ -f "$META_XLS" && -f "$SEQ_FASTA" ]] || { echo "โ Could not locate metadata/Fasta files" >&2; exit 1; }

# โโโโโโโโโโโโโโโโโโโโ Copy FHI build overlay โโโโโโโโโโโโโโ
echo "โ๏ธ  Preparing customised Nextstrain build files โฆ"
cp -R "${NGS_SCRIPTS}/nextstrain/influenza/avian_flu/." "$AVIAN_REPO/"

# โโโโโโโโโโโโโโโโโโโโ Prepare local data โโโโโโโโโโโโโโโโโโ
SCRIPT_DIR="${NGS_SCRIPTS}/nextstrain/avian_flu"
OUTDATA_DIR="${AVIAN_REPO}/local_data"
mkdir -p "$OUTDATA_DIR"

"$SCRIPT_DIR/convert_xls_to_tsv.sh" "$META_XLS"
python3 "$SCRIPT_DIR/process_metadata.py" output.tsv "$OUTDATA_DIR/metadata.tsv"
python3 "$SCRIPT_DIR/split_fasta_by_segment.py" "$SEQ_FASTA" --output-dir "$OUTDATA_DIR"

# โโโโโโโโโโโโโโโโโโโโ Run Snakemake build โโโโโโโโโโโโโโโโโ
pushd "$AVIAN_REPO" >/dev/null
CORES="$(nproc --ignore 1 || echo 1)"
echo "๐ Launching Snakemake with $CORES CPU(s) โฆ"
snakemake --cores "$CORES" -s genome-focused/Snakefile --printshellcmds --rerun-incomplete
popd >/dev/null

# โโโโโโโโโโโโโโโโโโโโ Collect & version outputs โโโโโโโโโโโ
echo "๐ฆ Collecting Auspice JSON files โฆ"
AUSPICE_DIR="$AVIAN_REPO/auspice"
for f in "$AUSPICE_DIR"/*.json; do
    base="$(basename "$f" .json)"
    cp "$f" "${OUT_DIR}/${base}_${DATE}.json"
    ln -sf "${OUT_DIR}/${base}_${DATE}.json" "${OUT_DIR}/${base}_latest.json"
done

# โโโโโโโโโโโโโโโโโโโโ Upload back to SMB โโโโโโโโโโโโโโโโโโ
echo "๐ค Uploading results to SMB share โฆ"
smbclient "$SMB_HOST" -A "$SMB_AUTH" -D "$SMB_TARGET" <<EOF
prompt OFF
recurse ON
lcd $OUT_DIR
mput *
EOF

echo "๐งน Cleaning up โฆ"
rm -rf "$WORK_DIR"

echo "โ Pipeline finished โ results in $OUT_DIR"
